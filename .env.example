# Queue: memory (single process) or redis (API + worker separate)
QUEUE_TYPE=memory
# Redis (when QUEUE_TYPE=redis)
# REDIS_URL=redis://localhost:6379/0
# REDIS_REQUEST_KEY=mobius:chat:requests
# REDIS_RESPONSE_KEY_PREFIX=mobius:chat:response:
# REDIS_RESPONSE_TTL_SECONDS=86400
# Storage for plans/responses: memory (persistence later)
STORAGE_BACKEND=memory
# Chat-specific config (CHAT_*). Default: Vertex AI. Set CHAT_LLM_PROVIDER=ollama for local Ollama.
# Use same credentials as Mobius RAG: copy from Mobius RAG/.env or set below.
# Vertex AI (same as Mobius RAG â€“ project mobiusos-new, service account in Mobius RAG folder)
VERTEX_PROJECT_ID=mobiusos-new
VERTEX_LOCATION=us-central1
VERTEX_MODEL=gemini-2.5-flash
# Path to service account JSON (Mobius RAG uses mobiusos-new-090a058b63d9.json in its root)
GOOGLE_APPLICATION_CREDENTIALS=../Mobius RAG/mobiusos-new-090a058b63d9.json
# Optional CHAT_* overrides (defaults use VERTEX_* above)
# CHAT_LLM_PROVIDER=vertex
# CHAT_LLM_MODEL=gemini-2.5-flash
# CHAT_LLM_TEMPERATURE=0.1
# CHAT_VERTEX_PROJECT_ID=mobiusos-new
# CHAT_VERTEX_LOCATION=us-central1
# CHAT_VERTEX_MODEL=gemini-2.5-flash
# CHAT_OLLAMA_BASE_URL=http://localhost:11434
# CHAT_OLLAMA_MODEL=llama3.1:8b
# CHAT_OLLAMA_NUM_PREDICT=8192
# Parser (patient vs non-patient keywords, comma-separated)
# CHAT_PARSER_PATIENT_KEYWORDS=my doctor,my medication,my visit
# Prompts (first-gen response)
# CHAT_PROMPT_FIRST_GEN_SYSTEM=You are a helpful assistant...
# CHAT_PROMPT_FIRST_GEN_USER=The user asked...
# API base URL for frontend (optional)
API_BASE_URL=http://localhost:8000
